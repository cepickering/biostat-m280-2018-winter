---
title: "BIOSTAT M280 HW2"
author: "Chad Pickering"
date: "2/16/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Q1

### Exercise 7.3.4

*Question 1*  

*Explore the distribution of each of the `x`, `y`, and `z` variables in `diamonds`. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.*  

We first plot the frequencies of measurements (in mm) of the three dimensions. We notice that the Z variable is concentrated between 2.5-5mm, whereas X and Y are very highly correlated, following almost exactly the same frequencies for the entire domain. The conclusion is that *Z is very likely the depth (height) of the diamond*, since from a birds' eye view, the length and width are essentially the same.   

```{r, message=FALSE}
library(tidyverse)
ggplot(diamonds) + 
  geom_freqpoly(mapping = aes(x = x, color = "X"), binwidth = 0.05) +
  geom_freqpoly(mapping = aes(x = y, color = "Y"), binwidth = 0.05) +
  geom_freqpoly(mapping = aes(x = z, color = "Z"), binwidth = 0.05) +
  coord_cartesian(xlim = c(2.5, 9)) +
  labs(title = "Frequency of Measurements of Dimensions of Diamonds",
       subtitle = "Bin width = 0.05mm",
       x = "Measurement (mm)",
       y = "Frequency") +
  theme(legend.position = "bottom") +
  scale_colour_discrete(name = "Dimension")
```

The following is a scatterplot of the length and width variables colored by the depth of the diamond. Despite a handful of points that do not follow the general approximate length=width trend (a few extreme outliers are obscured from view - these seem like data entry errors). As length/width increase, so does depth, quite linearly at that. We assert that X is length and Y is width - these terms can be interchanged, but the meaning will not be lost. An interesting observation is that out of 53940 diamonds, only 17 of them have an equal length and width.  

```{r}
z_common <- diamonds %>% 
  filter(z > 2 & z < 6) 
ggplot(z_common) +
  geom_point(mapping = aes(x = x, y = y, color = z)) + 
  coord_cartesian(xlim = c(3, 11), ylim = c(3, 11)) +
  labs(title = "Length vs. Width of Diamonds by Depth (mm)",
       x = "X (length) (mm)",
       y = "Y (width) (mm)") +
  theme(legend.position = "right") +
  scale_colour_continuous(name = "Z (depth)")
```

*Question 2*  

*Explore the distribution of `price`. Do you discover anything unusual or surprising? (Hint: Carefully think about the `binwidth` and make sure you try a wide range of values.)*  

We first plot the frequencies of prices with a bin width of 500 dollars. We see a positively skew, with a peak at about 1000 dollars and a gradual decreasing trend with few diamonds costing over 15000 dollars. Let's decrease the bin width to 100 dollars.  

```{r}
ggplot(diamonds) + 
  geom_freqpoly(mapping = aes(x = price), binwidth = 500) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $500",
       x = "Cost (dollars)",
       y = "Frequency")
```

With the bin width decreased to 100 dollars, we see that around 1500 dollars, very few observations are recorded, which is very strange, given that 1000 observations are recorded per bin in regions adjacent to it. Let's isolate that part of the dataset and confirm.  

```{r}
price_zoom_out <- ggplot(diamonds) + 
  geom_freqpoly(mapping = aes(x = price), binwidth = 100) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $100",
       x = "Cost (dollars)",
       y = "Frequency")

price_zoom_in <- ggplot(diamonds) + 
  geom_freqpoly(mapping = aes(x = price), binwidth = 100) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $100; zoomed to region of interest",
       x = "Cost (dollars)",
       y = "Frequency") +
  coord_cartesian(xlim = c(500, 2500))
  
require(gridExtra)
grid.arrange(price_zoom_out, price_zoom_in, nrow=2)
```

Indeed, below we see that there are no diamonds with prices between 1455 and 1545 dollars in the dataset. No other anomalies are spotted.  

```{r}
price_order <- diamonds %>%
  filter(price > 1453 & price < 1547) %>%
  select(price, x, y, z) %>%
  arrange(price)
head(price_order, 10)
```

*Question 3*  

*How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?*  

There are 23 0.99 carat diamonds in the dataset, while there are 1558 1 carat diamonds. Let's investigate possible causes of the difference - are 0.99 carat diamonds more rare? What are their properties in comparison with the 1 carat diamonds?  

```{r}
diamonds$xy_dist <- abs(diamonds$x - diamonds$y)

carat_99 <- diamonds %>%
  filter(carat == 0.99) %>%
  select(carat, price, x, y, z, xy_dist, cut, clarity)
carat_1 <- diamonds %>%
  filter(carat == 1) %>%
  select(carat, price, x, y, z, xy_dist, cut, clarity)
ct_lbl <- c("0.99 carat", "1 carat")
ct_count <- c(nrow(carat_99), nrow(carat_1))
ct_df <- as.data.frame(rbind(ct_lbl, ct_count))
row.names(ct_df) <- NULL
colnames(ct_df) <- NULL
ct_df
```

Both types of diamond have insignificant differences in their mean dimensions, but their mean price is significantly different (this is most likely a result, at least in part, of the fact that the carat value is not ideal, etc.). Let's see if the distributions of categorical cut and clarity measures are different between them.  

```{r}
t.test(carat_99$price, carat_1$price)
```

Here, we see that the proportion of 0.99 carat diamonds with lower quality cuts are higher than that of 1 carat diamonds.  *FINISH PLOT*

```{r}
carat_int <- rbind(carat_99, carat_1)
carat_int$carat <- as.factor(carat_int$carat)
ggplot(data = carat_int) + 
  geom_bar(mapping = aes(x = cut, fill = carat, y = ..prop..), position = "dodge")
```

*Question 4*  

Compare and contrast `coord_cartesian()` vs `xlim()` or `ylim()` when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?  

The following uses `coord_cartesian()` with an unset binwidth. In this case, it defaults to 30. Let's zoom in to the domain [0, 5000] so that only half of a bar should show.  

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = price)) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $500",
       x = "Cost (dollars)",
       y = "Frequency")
```

This seems to preserve the bin width to the default of the original histogram.  

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = price)) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $500",
       x = "Cost (dollars)",
       y = "Frequency") +
  coord_cartesian(xlim = c(0, 5000))
```

Using xlim() or ylim() removes rows if those observations are not shown in the plot. Additionally, the bin widths are rescaled to fit the new domain, with a default of 30.  

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = price)) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $500",
       x = "Cost (dollars)",
       y = "Frequency") +
  xlim(0, 5000)
```

### Exercise 7.4.1

*Question 1*  

*What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference?*  

In a histogram, the rows where missing values are present are removed, and these values are not displayed.  

```{r}
diamonds2 <- diamonds %>% 
  mutate(z = ifelse(z < 2 | z > 6, NA, z))

all_z <- ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = z), binwidth = 0.05) +
  labs(title = "Frequency of Heights of Diamonds",
       subtitle = "All z values included",
       x = "Depth (mm)",
       y = "Frequency") +
  coord_cartesian(xlim = c(5.5, 6.5), ylim = c(0, 50))

most_z <- ggplot(diamonds2) + 
  geom_histogram(mapping = aes(x = z), binwidth = 0.05) +
  labs(title = "Frequency of Heights of Diamonds",
       subtitle = "All z>6 excluded",
       x = "Depth (mm)",
       y = "Frequency") +
  coord_cartesian(xlim = c(5.5, 6.5), ylim = c(0, 50))

grid.arrange(all_z, most_z, nrow=2)
```

Here, we set all fair cut diamonds' "Cut" variable to NA and create bar plots. The category "Fair" is removed and replaced with the "NA" category, which has an identical count as "Fair" from the original dataset. This is because "NA" becomes an ordinal category, a factor; it is not removed from consideration in a bar plot.  

```{r}
diamonds3 <- diamonds %>% 
  mutate(cut = replace(cut, cut=="Fair", NA))

all_cut <- ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut)) +
  labs(title = "Counts of Types of Diamond Cut",
       subtitle = "All cuts included",
       x = "Cut",
       y = "Count")

most_cut <- ggplot(data = diamonds3) + 
  geom_bar(mapping = aes(x = cut)) +
  labs(title = "Counts of Types of Diamond Cut",
       subtitle = "Fair cuts excluded",
       x = "Cut",
       y = "Count")

grid.arrange(all_cut, most_cut, nrow=2)
```

*Question 2*  

What does `na.rm = TRUE` do in `mean()` and `sum()`?  

Let's take the first 500 values of `x` in the length column and set all of the values over 6 to NA. Taking the mean or sum of the vector that includes the NAs gives NA because when adding NA into the sum, the result is not a numerical value. However, the denominator of the mean still counts all values, including the NAs. The function `na.rm()` strips all NA values from consideration, reducing the count of values in the mean as well.  

```{r}
x_vec <- diamonds$x[1:500]
x_vec_na <- x_vec
x_vec_na[x_vec_na > 6] <- NA
c(mean(x_vec_na), sum(x_vec_na)) # na.rm = FALSE
c(mean(x_vec_na, na.rm = TRUE), sum(x_vec_na, na.rm = TRUE))
```

### Exercise 7.5.1.1

*Question 1*  

*Use what you’ve learned to improve the visualisation of the departure times of cancelled vs. non-cancelled flights.*  

In the improved visualization, we use superimposed density curves to analyze the approximate relative frequency of departing (non-cancelled) flights compared to cancelled flights. We see given a flight is cancelled, it is likely that its departure time was between about 2-8pm rather than earlier in the day. We can see that the proportion of non-cancelled flights is bimodal, peaking in the early-mid morning, and again later in the day, while there are a low relative proportion of cancelled flights early in the day and a high relative proportion later in the day (compared to non-cancelled flights).  

```{r}
library(nycflights13)

# # Density - frequency-based
# flights %>%
#   mutate(
#     cancelled = is.na(dep_time),
#     sched_hour = sched_dep_time %/% 100,
#     sched_min = sched_dep_time %% 100,
#     sched_dep_time = sched_hour + sched_min / 60
#   ) %>% 
#   ggplot(mapping = aes(x = sched_dep_time, y = ..density..)) + 
#     geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/2)

# Density - smoothed (preferred)
flights %>%
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>% 
  ggplot(mapping = aes(x=sched_dep_time, fill = cancelled)) +
    geom_density(stat = "density", alpha = 0.4, position = "identity") +
    labs(title = "Densities of Cancelled and Non-cancelled Flights",
       subtitle = "Proportions relative to groups",
       x = "Hour",
       y = "Density")
```

*Question 2*  

*What variable in the diamonds dataset is most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?*  

Without doing a backwards model selection procedure to find the best predictive multivariate model, I merely removed the categorical variables from the dataset and found the variable whose correlation with `price` was the highest. In this case, it was `carat`. We see that as `carat` increases, `price` does too, on average.  

```{r}
d <- diamonds[ ,-c(2, 3, 4, 11)]
cor(d)
```

```{r}
ggplot(diamonds) +
  geom_point(mapping = aes(x = carat, y = price)) + 
  geom_smooth(mapping = aes(x = carat, y = price), se = FALSE) +
  labs(title = "Carat vs. Price of Diamonds",
       x = "Carat",
       y = "Price (dollars)")
```

Exploring the correlation of `carat` with `cut`, we find that "fair" diamonds have a larger `carat` value on average, and "ideal" diamonds having the lowest average `carat` value. However, we can see by the densities in the second plot that the "ideal" diamonds have the most positively skewed distribution while the other four categories have approximately the same skew. Correlation between `carat` and `cut` is mild at best.  

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot(mapping = aes(x = cut, y = carat)) + 
    geom_boxplot() +
    coord_flip() +
  labs(title = "Carat per Cut Rating of Diamonds",
       x = "Carat",
       y = "Cut")
```

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot(mapping = aes(x=carat, fill = cut)) + 
    geom_density(stat = "density", alpha = 0.5, position = "identity") + 
    facet_wrap(~ cut, nrow = 5) +
  labs(title = "Carat per Cut of Diamonds",
       x = "Carat",
       y = "Density")
```

Finally, we will show the relationship between `price` and `cut` to piece everything together. We see the counter-intuitive relationship that as cut increases in quality, the average price drops. So, we can say that there is a mild trend of the following: as carat increases, cut decreases, and thus price increases.  

```{r}
diamonds %>%
  select(price, cut) %>%
  ggplot(mapping = aes(x = price, fill = cut)) + 
    geom_density(stat = "density", alpha = 0.5, position = "identity") + 
    facet_wrap(~ cut, nrow = 5) +
  labs(title = "Price per Cut of Diamonds",
       x = "Price (dollars)",
       y = "Density")
```

*Question 3*  

*Install the ggstance package, and create a horizontal boxplot. How does this compare to using `coord_flip()`?*  

The following is from the previous question. We stripped the `coord_flip()` function out of the code so that the original version is displays. Following it, we use `coord_flip()`.

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot(mapping = aes(x = cut, y = carat)) + 
    geom_boxplot() +
  labs(title = "Carat per Cut Rating of Diamonds",
       x = "Carat",
       y = "Cut")
```

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot(mapping = aes(x = cut, y = carat)) + 
    geom_boxplot() +
    coord_flip() +
  labs(title = "Carat per Cut Rating of Diamonds",
       x = "Carat",
       y = "Cut")
```

A horizontal boxplot created with the `ggstance` package appears the same as a boxplot created with `ggplot2` with the `coord_flip()` option.  

```{r}
library(ggstance)
diamonds %>%
  select(carat, cut) %>%
  ggplot(aes(carat, cut)) +
    geom_boxploth()
```

*Exercise 4*  

*One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs cut. What do you learn? How do you interpret the plots?*  

First, let's plot the boxplots with the `geom_boxplot()` appendage. The `geom_lv()` boxplot follows. In my opinion, both are abhorrent and density plots should be used instead. Both sets of boxplots show the high price variance in all cut categories with the highest median cost in the "fair" category. The "fair" category also has fewer outliers than the other categories, shown in the `geom_lv()` plot by a tube that tapers faster. This is hardly better than the other plot - the only benefit is that you can visually see the tapering if you look hard enough; in the standard boxplot, the density of the dots is such that you cannot tell how many outliers there really are.  

```{r}
diamonds %>%
  select(price, cut) %>%
  ggplot(mapping = aes(x = cut, y = price)) + 
    geom_boxplot() +
    coord_flip() +
  labs(title = "Price per Cut Rating of Diamonds",
       x = "Price (dollars)",
       y = "Cut")
```

```{r}
library(lvplot)
diamonds %>%
  select(price, cut) %>%
  ggplot(mapping = aes(x = cut, y = price)) + 
    geom_lv(mapping = aes(x = cut, y = price)) +
    coord_flip() +
  labs(title = "Price per Cut Rating of Diamonds",
       x = "Price (dollars)",
       y = "Cut")
```

*Exercise 5*  

*Compare and contrast `geom_violin()` with a facetted `geom_histogram()`, or a coloured `geom_freqpoly()`. What are the pros and cons of each method?*  

`geom_violin()` is below. Pros: Shows density as width; approximate variance is clear; extreme outlier distance shown. Cons: Specific points not shown, including quartiles or individual outliers; differences in frequencies between groups is lost.    

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot(mapping = aes(x = cut, y = carat)) + 
    geom_violin() +
    coord_flip() +
  labs(title = "Carat per Cut Rating of Diamonds",
       x = "Cut",
       y = "Carat")
```

Faceted `geom_histogram()` is below. Pros: Separates categories for clear side-by-side comparison; frequencies can be easily compared; binwidth can be manipulated for better understanding of distribution. Cons: Outliers too small to be seen/shown; if there are many groups, comparison in a grid could grow troublesome.  

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot() + 
    geom_histogram(mapping = aes(x = carat), binwidth = 0.05) +
    facet_wrap(~ cut, nrow = 5) +
  labs(title = "Carat per Cut Rating of Diamonds",
       x = "Carat",
       y = "Count")
```

`geom_freqpoly()` is below. Pros: Frequencies are directly compared; variance is clear, as well as outliers; colors help groups stand out. Cons: with many groups, the plot could get too crowded to interpret.      

```{r}
diamonds %>%
  select(carat, cut) %>%
  ggplot() + 
    geom_freqpoly(mapping = aes(x = carat, color = cut), binwidth = 0.05) +
    coord_cartesian(xlim = c(0, 3)) +
  labs(title = "Carat per Cut Rating of Diamonds",
       x = "Carat",
       y = "Count")
```

*Exercise 6*  

*If you have a small dataset, it’s sometimes useful to use geom_jitter() to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.*  

NEEDS WORK

In the function `geom_beeswarm()`, the argument `groupOnX` adds jitter to the x axis if TRUE.

```{r}
library(ggbeeswarm)
d_sub <- sample_n(diamonds, 50, replace = FALSE)

```

### Exercise 7.5.2.1

*Exercise 1*  

*How could you rescale the count dataset above to more clearly show the distribution of cut within colour, or colour within cut?*  

I don't know what rescale means in this context, or how transforming the counts would produce a more informative plot, but the following visualization does a much better job at showing the distribution of counts within color categories, and how the distribution of the cuts peaks as color varies from colorless (D) to nearly faint color (J). We then show a similar plot, except featuring proportions within categories.  

```{r}
ggplot(data = diamonds) + 
    geom_bar(mapping = aes(x = color, fill = cut), position = "dodge")
```

```{r}
# Redo plot above with proportions


```

*Exercise 2*  

*Use geom_tile() together with dplyr to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?*  

The number of destinations listed makes this plot impossible to read (just below). The only information you can get from this is that delays increase in the summer months and in December in general across all regions. An improvement is below - I make 4 plots to spread out the rows instead of having a more compact version. We could also make a plot using `geom_freqpoly()` and separate out the destinations with a facet wrap.  

```{r}
summarise(group_by(flights, dest, month), delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(mapping = aes(x = month, y = dest)) + 
    geom_tile(mapping = aes(fill = delay)) +
  labs(title = "Price per Cut Rating of Diamonds",
       x = "Price (dollars)",
       y = "Cut")
```

```{r}
tile_a <- summarise(group_by(flights, dest, month), delay = mean(dep_delay, na.rm = TRUE)) %>%
  filter(grepl('^[A-D]', dest)) %>%
  ggplot(mapping = aes(x = month, y = dest)) + 
    geom_tile(mapping = aes(fill = delay)) +
  labs(title = "Average Delay per Destination per Month",
       x = "Month",
       y = "Destination")
```

```{r}
tile_b <- summarise(group_by(flights, dest, month), delay = mean(dep_delay, na.rm = TRUE)) %>%
  filter(grepl('^[E-L]', dest)) %>%
  ggplot(mapping = aes(x = month, y = dest)) + 
    geom_tile(mapping = aes(fill = delay)) +
  labs(title = "Average Delay per Destination per Month",
       x = "Month",
       y = "Destination")
```

```{r}
tile_c <- summarise(group_by(flights, dest, month), delay = mean(dep_delay, na.rm = TRUE)) %>%
  filter(grepl('^[M-R]', dest)) %>%
  ggplot(mapping = aes(x = month, y = dest)) + 
    geom_tile(mapping = aes(fill = delay)) +
  labs(title = "Average Delay per Destination per Month",
       x = "Month",
       y = "Destination")
```

```{r}
tile_d <- summarise(group_by(flights, dest, month), delay = mean(dep_delay, na.rm = TRUE)) %>%
  filter(grepl('^[S-Z]', dest)) %>%
  ggplot(mapping = aes(x = month, y = dest)) + 
    geom_tile(mapping = aes(fill = delay)) +
  labs(title = "Average Delay per Destination per Month",
       x = "Month",
       y = "Destination")
```


*Exercise 3*  

*Why is it slightly better to use `aes(x = color, y = cut)` rather than `aes(x = cut, y = color)` in the example above?*  

Using the latter, we see that the colors are ordered in reverse and that the area of the individual boxes are less square because of the number of categories relative to the shape of the entire plot.  

```{r}
diamonds %>% 
  count(color, cut) %>%  
  ggplot(mapping = aes(x = cut, y = color)) +
    geom_tile(mapping = aes(fill = n))
```

### Exercise 7.5.3.1

*Exercise 1*  

*Instead of summarising the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs cut_number()? How does that impact a visualisation of the 2d distribution of carat and price?*  

```{r}
ggplot(diamonds) + 
  geom_freqpoly(mapping = aes(x = price), binwidth = 500) +
  labs(title = "Frequency of Prices of Diamonds",
       subtitle = "Bin width = $500",
       x = "Cost (dollars)",
       y = "Frequency")
```

*Exercise 2*  

*Visualise the distribution of carat, partitioned by price.*  

```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = carat)) + 
  geom_boxplot(mapping = aes(group = cut_width(price, 1000))) +
  labs(title = "Distribution of Carat of Diamonds",
       subtitle = "Price bins of $1000",
       x = "Cost (dollars)",
       y = "Carat")
```

*Exercise 3*  

*How does the price distribution of very large diamonds compare to small diamonds. Is it as you expect, or does it surprise you?*  

The largest 10% of diamonds have a median price of about 13000 dollars with a rather high variance and a mildly negatively skewed distribution. The smallest 10% of diamonds have a median price of about 1000 dollars with a positively skewed distribution and prices concentrated below 2500 dollars. This seems fairly expected.  

```{r}
ggplot(data = diamonds, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_number(carat, 10))) +
  labs(title = "Distribution of Price of Diamonds",
       subtitle = "Carat bins of 0.5",
       x = "Carat",
       y = "Cost (dollars)")
```

If we study the distributions of the boxplots when `carat` is divided in half-carat increments, we see that for diamonds with size 2 carats or higher, the median hits a peak and stabilizes while the variance decreases as carat increases.   

```{r}
ggplot(data = diamonds, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.5))) +
  labs(title = "Distribution of Price of Diamonds",
       subtitle = "Carat bins of 0.5",
       x = "Carat",
       y = "Cost (dollars)")
```

*Exercise 4*  

*Combine two of the techniques you’ve learned to visualise the combined distribution of cut, carat, and price.*  

Combining the techniques of using `cut_width()` with boxplots and facet wrapping, we can see clearly the distributions of price vs. carat value per cut type.  

```{r}
ggplot(data = diamonds, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.5))) +
  facet_wrap(~ cut, nrow = 2) +
  labs(title = "Distribution of Price of Diamonds",
       subtitle = "Carat bins of 0.5",
       x = "Carat",
       y = "Cost (dollars)")
```

*Exercise 5*  

*Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the plot below have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately.*  

```{r}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = x, y = y)) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```

*Why is a scatterplot a better display than a binned plot for this case?*  

Looking at the above plot in, say, a univariate boxplot of X or Y will show approximately the same distribution (about the same median and IQR) with the few exceptions of the occasional outliers. If we take an X that is well within the domain of points observed, 6.6 for example, we notice that most Y  observations occur around 6.6, but some occur between 4 and 6. Without a bivariate plot, the conditional distributions, X|Y and Y|X, are lost; only observations that are outliers in the design space (X) or outliers in Y are indicated separately. It is necessary to look at how the variables covary to spot real outliers, those that are unusual in one dimension when you interpolate within the range of the other.  

## Q3

Redo HW1 Q2 using functions in tidyverse:  

### Question 1.  

**How many persons are in the data set (statisticians call this `n`)?**  

Assuming each row is a unique person, we find **959** people (the command `uniq` is used anyway, just in case).  

**How many SNPs are in the data set (statisticians call this `p`)?**  

Assuming each row is a unique SNP, we find **8348674** SNPs (the command `uniq` is used anyway, just in case).

### Question 2.  

**Which chromosomes does this data set contain?**  



**How many SNPs are in each chromosome?** 



### Question 3.  

**MAP4 (microtubule-associated protein 4) is a gene on chromosome 3 spanning positions 47,892,180 bp -- 48,130,769 bp. How many SNPs are located within MAP4 gene?**  



**894** SNPs are located within the MAP4 gene.  

### Question 4.

**Statistical geneticists often have to reformat a data set to feed into various analysis programs. For example, to use the Mendel software we have to reformat the data set to be read by Mendel. Mendel's SNP definition file is similar to the plink `bim` file but has format `SNP ID`, `Chromosome`, `Base Pair Position` with each field separated by a comma. Write a Linux shell command to convert `merge-geno.bim` to Mendel SNP definition file.**   
      

    
**Mendel's pedigree file is similar to the plink `fam` file but has format `Family ID`, `Person ID`, `Father ID`, `Mother ID`, `Sex` coded as M or F, `Twin Status` with each field separated by a comma. Write a Linux shell command to convert `merge-geno.fam` to Mendel pedigree file. Since twin status is not available in plink format, we put nothing for that field. Also Mendel limits Person ID to have length less than or equal to 8 characters, so we have to strip the string `T2DG` from the IDs.**  






